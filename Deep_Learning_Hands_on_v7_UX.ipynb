{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep_Learning_Hands_on_v7 - UX.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Kbcoog8wUeBF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Jornada Paulista de Radiologia 2018\n",
        "\n",
        "# Hands-on - Deep Learning para detectar hemorragia intracraniana\n",
        "\n",
        "\n",
        "\n",
        "**Desenvolvido por:**\n",
        "\n",
        "Felipe Campos Kitamura (kitamura.felipe@gmail.com)\n",
        "\n",
        "Igor Santos (igorafael87@gmail.com)\n",
        "\n",
        "Thiago Julio\n",
        "\n",
        "Luciano Prevedello\n",
        "\n",
        "\n",
        "**Instrutores:**\n",
        "\n",
        "Marcelo Froeder\n",
        "\n",
        "Daisy Kase\n",
        "\n",
        "José Eduardo Venson\n",
        "\n",
        "\n",
        "**Agradecimento:**\n",
        "\n",
        "Marcelo Felix\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "R7EnOa6MUeBG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**OBJETIVO:**\n",
        "\n",
        "Demonstrar os passos básicos do treinamento de uma rede neural convolucional para detectar hemorragia intracraniana.\n"
      ]
    },
    {
      "metadata": {
        "id": "fIt6E6YWUeBH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Passo a passo:**\n",
        "\n",
        "Todo o processo será realizado com a linguagem de programação Python, versão 3.\n",
        "\n",
        "O dataset utilizado consiste em cerca de 100 imagens de tomografias de crânio normais e 100 imagens com sangramento intracraniano.\n",
        "\n",
        "Para tarefas específicas importaremos bibliotecas específicas."
      ]
    },
    {
      "metadata": {
        "id": "u-qAsa1iUeBH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Passo 1: criando o dataset"
      ]
    },
    {
      "metadata": {
        "id": "MbCekwyoioXz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "def printmd(string):\n",
        "    display(Markdown(string))\n",
        "    \n",
        "#Primeiro vamos baixar o nosso dataset. Você pode baixar esse arquivo no seu computador para ver as imagens que utilizaremos nesse hands-on.\n",
        "!wget https://github.com/igorafaelms/deeplearningddi/blob/master/Cranio.zip?raw=true\n",
        "\n",
        "print ('\\033[1m' + 'Etapa Concluída. Vá para o próximo comando!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qF6wLG_dioqX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Agora vamos extrair os arquivos de imagens de dentro desse arquivo .zip\n",
        "!unzip -o Cranio.zip?raw=true -d /\n",
        "\n",
        "print ('\\n' + '\\033[1m' + 'Etapa Concluída. Vá para o próximo comando!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B1Iy0zOAUeBI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Para abrir as imagens .jpg, utilizaremos o glob, que lista os arquivos que existem dentro de uma pasta\n",
        "\n",
        "from glob import glob\n",
        "\n",
        "print ('\\033[1m' + 'Etapa Concluída. Vá para o próximo comando!')\n",
        "\n",
        "#Para executar cada célula, pressione SHIFT + ENTER"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHMr3gvuUeBL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Vamos definir o caminho das pastas que contém as imagens\n",
        "hematoma_dir = '/Cranio/Hematoma/*.png'\n",
        "normal_dir = '/Cranio/Normal/*.png'\n",
        "\n",
        "#Agora vamos listar os arquvos dentro de cada uma das pastas, usando o glob()\n",
        "hematoma_lista = glob(hematoma_dir)\n",
        "normal_lista = glob(normal_dir)\n",
        "\n",
        "#Para termos ideia do número de arquivos em cada pasta, vamos dar um print(len(lista)))\n",
        "print('Número de casos com hematoma: ', len(hematoma_lista))\n",
        "print('Número de casos sem hematoma: ', len(normal_lista))\n",
        "\n",
        "print ('\\n' + '\\033[1m' + 'Etapa Concluída. Vá para o próximo comando!')\n",
        "\n",
        "#Execute esse código com SHIFT + ENTER\n",
        "\n",
        "#A saída esperada é\n",
        "\n",
        "#Número de casos com hematoma:  100\n",
        "#Número de casos sem hematoma:  100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T-bfbWn9UeBO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Para ter ideia de como é a lista de arquivos gerada pelo glob, vamos olhar a variável hematoma_lista\n",
        "hematoma_lista\n",
        "print(*hematoma_lista, sep = \"\\n\")\n",
        "\n",
        "print ('\\n' + '\\033[1m' + 'Etapa Concluída. Vá para o próximo comando!')\n",
        "\n",
        "#Execute esse código com SHIFT + ENTER"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nLBbVVrEUeBQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Como o computador enxerga uma imagem?**\n",
        "\n",
        "Considere cada imagem como uma matriz em que o valor de cada pixel corresponde a um \n",
        "número que determina o tom de cinza da imagem.\n"
      ]
    },
    {
      "metadata": {
        "id": "YPRYbFl3UeBR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Podemos também ver cada uma das imagens do nosso dataset. Para isso, precisaremos abrir um aquivo .png e plotá-lo num gráfico.\n",
        "\n",
        "#Para abrir o arquivo de imagem, utilizaremos o openCV, uma biblioteca aberta de visão computacional\n",
        "\n",
        "import cv2\n",
        "\n",
        "#Utilizaremos uma biblioteca de plotagem de gráficos chamada a matplotlib\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#Mãos a obra, vamos abrir um arquivo como exemplo:\n",
        "\n",
        "ID_arquivo = 4\n",
        "\n",
        "imagem = cv2.imread(hematoma_lista[ID_arquivo])\n",
        "\n",
        "#Esse comando é só para ler o arquivo. Agora vamos criar uma figura com a imagem que abrimos (plotar a imagem):\n",
        "\n",
        "plt.imshow(imagem)\n",
        "plt.show()\n",
        "\n",
        "print ('\\n' + '\\033[1m' + 'Etapa Concluída. Vá para o próximo comando!')\n",
        "\n",
        "\n",
        "#Execute esse código com SHIFT + ENTER\n",
        "\n",
        "#Tente modificar ID_arquivo com outros números para vizualizar outras imagens. Repare no tamanho de cada imagem"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nwjuot4_UeBT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Repare que cada imagem tem um tamanho diferente. \n",
        "\n",
        "#Como as redes neurais tem entrada de tamanho fixo, precisaremos redimensionar todas elas para um tamanho único.\n",
        "\n",
        "#Além disso, precisamos informar explicitamente a qual das categorias as imagens pertecem em uma lista chamada labels (hematoma = 1, normal = 0)\n",
        "\n",
        "#Faremos isso ao mesmo tempo que salvaremos as imagens numa matriz. Para usar matrizes, importaremos a NumPy.\n",
        "\n",
        "# Por que usamos matrizes? A entrada de informações nas redes neurais se dá nesse formato,\n",
        "# pois permite processamento computacional paralelo e maior velocidade de processamento.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "dataset = [] # cria uma lista vazia para incluir as imagens do dataset\n",
        "labels = [] # cria uma lista vazia para incluir a categoria a qual cada imagem pertence (0 ou 1)\n",
        "\n",
        "for arquivo in hematoma_lista: # para cada arquivo de imagem na lista hematoma:\n",
        "    img = cv2.imread(arquivo, cv2.IMREAD_GRAYSCALE) #abre o arquivo como escala de cinzas e coloca a imagem na variável img\n",
        "    img = cv2.resize(img, (256,256)) #redimensiona a imagem para 256 x 256 e salva na mesma variável img\n",
        "    dataset.append(img) #adiciona essa imagem na lista do dataset e \n",
        "    labels.append(1) #informa que ela é um caso de hematoma (1)\n",
        "\n",
        "#Agora faremos o mesmo para as imagens sem sangramento\n",
        "\n",
        "for arquivo in normal_lista: # para cada arquivo de imagem na lista hematoma:\n",
        "    img = cv2.imread(arquivo, cv2.IMREAD_GRAYSCALE) #abre o arquivo como escala de cinzas e coloca a imagem na variável img\n",
        "    img = cv2.resize(img, (256,256)) #redimensiona a imagem para 256 x 256 e salva na mesma variável img\n",
        "    dataset.append(img) #adiciona essa imagem na lista do dataset e \n",
        "    labels.append(0) #informa que ela é um caso normal (0)\n",
        "    \n",
        "dataset = np.asarray(dataset, dtype=np.float32) #transforma a lista de variáveis numa matriz\n",
        "labels = np.asarray(labels)\n",
        "\n",
        "for i in range(len(dataset)):\n",
        "  dataset[i] = (dataset[i] - np.average(dataset[i], axis= (0, 1))) / np.std(dataset[i], axis= (0, 1))\n",
        "\n",
        "#Vamos ver qual o tamanho dessa matriz 'dataset'\n",
        "\n",
        "#Esperamos que a primeira dimensão dela seja de 200 (100 casos de hematoma e 100 normais)\n",
        "\n",
        "#A segunda e a terceira dimensões devem ser 256.\n",
        "\n",
        "#Execute esse código com SHIFT + ENTER\n",
        "print(dataset.shape)\n",
        "\n",
        "print ('\\n' + '\\033[1m' + 'Etapa Concluída. Vá para o próximo comando!')\n",
        "\n",
        "# a saída esperada é (200, 256, 256)\n",
        "\n",
        "# Colocar exemplo de uma matriz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PA2NK3_HUeBV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Passo 2: criando a estrutura da rede neural convolucional"
      ]
    },
    {
      "metadata": {
        "id": "u2R8IIKOUeBW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Uma convolução é uma operação matemátca que consiste em multiplicar uma matriz (a nossa imagem) por um \n",
        "filtro (matrix de pesos)\n"
      ]
    },
    {
      "metadata": {
        "id": "cievFBO1UeBW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Para criar a rede neural convolucional, utilizaremos o Keras, que é uma biblioteca para Deep Learning em Python\n",
        "\n",
        "#Inicialmente vamos importar as funções do Keras que iremos utilizar:\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers.core import Dense, Dropout\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPool2D, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Concatenate, add\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Activation, Dense, LeakyReLU\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#Agora criaremos a estrutura da rede neural convolucional\n",
        "\n",
        "#Essa é a definição da camada de entrada da rede\n",
        "#Lembra que a nossa matriz com todas as imagens de cada categoria tem o formato (200, 256, 256)?\n",
        "#Nesse caso a entrada (input) da rede é cada imagem individualmente\n",
        "#Ou seja, uma imagem de tamanho 256 x 256 pixels e 1 canal de cor (escala de cinzas)\n",
        "\n",
        "imgs = Input(shape=(256,256,1))\n",
        "\n",
        "#Abaixo temos a primeira camada Convolucional\n",
        "\n",
        "\n",
        "x = Conv2D(8, 3, padding='same', activation='relu')(imgs)\n",
        "\n",
        "#Em seguida, adicionamos uma camada MaxPool, que irá reduzir em 75% o tamanho da saída da camada convolucional.\n",
        "#Fazemos isso para evitar que o número de parâmetros da rede aumente demais.\n",
        "#Não se preocupe em entender o detalhe de cada uma dessas operações. Tente captar a ideia geral.\n",
        "x = MaxPool2D()(x)\n",
        "\n",
        "#Adicionaremos mais camadas convolucionais, seguidas de MaxPool\n",
        "\n",
        "x = Conv2D(8, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPool2D()(x)\n",
        "x = Conv2D(8, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPool2D()(x)\n",
        "x = Conv2D(8, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPool2D()(x)\n",
        "x = Conv2D(8, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPool2D()(x)\n",
        "x = Conv2D(8, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPool2D()(x)\n",
        "x = Conv2D(10, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPool2D()(x)\n",
        "x = Conv2D(10, 3, padding='same', activation='relu')(x)\n",
        "x = MaxPool2D()(x)\n",
        "x = Conv2D(12, 3, padding='same', activation='relu')(x)\n",
        "x = Conv2D(12, 3, padding='same', activation='relu')(x)\n",
        "x = Conv2D(12, 3, padding='same', activation='relu')(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "\n",
        "#Finalmente adicionaremos duas camadas densas, ou 'Fully Connected Layers'.\n",
        "#Essas camadas são redes neurais convencionais, sem convolução.\n",
        "#Não se preocupe com o porquê de usarmos essa camada agora.\n",
        "x = Dense(64, activation='relu')(x)\n",
        "\n",
        "#Dropout é uma maneira de reduzir overfitting.\n",
        "x = Dropout(0.6)(x)\n",
        "\n",
        "#Definiremos agora a entrada e a saída da rede\n",
        "#A função Dense tem o argumento \"1\" pois a saída da rede é a classificação hematoma x não-hematoma\n",
        "#Ou seja, a saída da rede é apenas um número (0 ou 1)\n",
        "\n",
        "x = Dense(32, activation='relu')(x)\n",
        "\n",
        "outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "inputs = imgs\n",
        "\n",
        "#Por fim, definimos a rede\n",
        "\n",
        "Rede_JPR = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "#Agora, definiremos o método de otimização da rede: ADAM, com a taxa de aprendizado e de decaimento\n",
        "#Cada um desses parâmetros é ajustável.\n",
        "\n",
        "custom_adam = optimizers.Adam(lr=0.0005, decay=0.0002)\n",
        "\n",
        "#Compila o modelo\n",
        "Rede_JPR.compile(loss='binary_crossentropy', optimizer=custom_adam, metrics=['acc'])\n",
        "\n",
        "print ('\\033[1m' + 'Etapa Concluída. Vá para o próximo comando!')\n",
        "\n",
        "#Execute esse código com SHIFT + ENTER"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iC4uu87DUeBZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Passo 3: Dividindo o dataset nos grupos Treinamento/Validação/Teste"
      ]
    },
    {
      "metadata": {
        "id": "gTnE2xwHUeBa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Vamos separar nosso dataset em grupos de treinamento, validação e test. Para isso, usaremos a biblioteca sklearn.\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "#Divide treino, validação e teste na proporção 80%/10%/10%\n",
        "\n",
        "dataset_train, dataset_test, labels_train, labels_test = train_test_split(dataset[:,...,np.newaxis], labels[:,...,np.newaxis], test_size=0.1, random_state=88)\n",
        "dataset_train, dataset_val, labels_train, labels_val = train_test_split(dataset_train, labels_train, test_size=0.11, random_state=88)\n",
        "\n",
        "#Mostra o tamanho das variáveis dos grupos\n",
        "\n",
        "print('(Número de imagens, Imagem_X, Imagem_Y, canais de cor) (Número de labels, 1)')\n",
        "print(dataset_train.shape, labels_train.shape)\n",
        "print(dataset_val.shape, labels_val.shape)\n",
        "print(dataset_test.shape, labels_test.shape)\n",
        "\n",
        "#Você deve ver a seguinte saída:\n",
        "\n",
        "#(160, 256, 256, 1) (160,1)\n",
        "#(20, 256, 256, 1) (20,1)\n",
        "#(20, 256, 256, 1) (20,1)\n",
        "\n",
        "print ('\\n' + '\\033[1m' + 'Etapa Concluída. Vá para o próximo comando!')\n",
        "\n",
        "#Execute esse código com SHIFT + ENTER"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ML6EuUk_UeBd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Passo 4: como treinar a sua rede neural"
      ]
    },
    {
      "metadata": {
        "id": "mnAn5bE8UeBe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Durante o treinamento da rede, os pesos das sinapses de todas as camadas são atualizados.\n",
        "\n",
        "Após a conclusão do treinamento, cada filtro representará uma característica de imagem a ser procurada nas imagens do nosso dataset."
      ]
    },
    {
      "metadata": {
        "id": "UsOO98YmUeBf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Hora de treinar a nossa rede neural.\n",
        "\n",
        "#Primeiro vamos definir para salvar o melhor modelo que for encontrado durante o treino\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='Melhor_modelo.hdf5', monitor='val_loss',\n",
        "                               verbose=1, save_best_only=True)\n",
        "\n",
        "#Muito bem, chegou a hora mais esperada, vamos treinar a nossa rede com o dataset que criamos\n",
        "\n",
        "print('Treinando a Rede_JPR:')\n",
        "\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "#datagen.fit(dataset_train)\n",
        "  \n",
        "\n",
        "\n",
        "#Definimos o treinamento com o dataset de treino, realizando validação no dataset de validação.\n",
        "#O treinamento não usa o dataset de teste\n",
        "\n",
        "Valida = (dataset_val, labels_val)\n",
        "\n",
        "hist = Rede_JPR.fit_generator(datagen.flow(dataset_train, labels_train, batch_size=20), steps_per_epoch=1*len(dataset_train) / 20, epochs=200, \n",
        "                    validation_data= (dataset_val, labels_val), \n",
        "                    callbacks=[checkpointer])\n",
        "\n",
        "#Por fim, plotamos os resultados de evolução da medida de erro (loss) ao longo das épocas\n",
        "\n",
        "plt.plot(hist.history['loss'], 'b-', label='train loss')\n",
        "plt.plot(hist.history['val_loss'], 'r-', label='val loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.plot(hist.history['acc'], 'b-', label='train accuracy')\n",
        "plt.plot(hist.history['val_acc'], 'r-', label='val accuracy')\n",
        "plt.ylabel('acc')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "\n",
        "del(Rede_JPR)\n",
        "print('Treino finalizado.')\n",
        "\n",
        "print ('\\n' + '\\033[1m' + 'Etapa Concluída. Vá para o próximo comando!')\n",
        "\n",
        "#Execute esse código com SHIFT + ENTER"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dWTfJB-dUeBi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Passo 5: avaliando sua rede no conjunto de Teste"
      ]
    },
    {
      "metadata": {
        "id": "XeuNqyylUeBj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Neste passo, iremos apresentar todo o dataset de treino para o modelo que criamos, de forma a calcular a acurácia da nossa rede neural no grupo de treino"
      ]
    },
    {
      "metadata": {
        "id": "xykHvjiaUeBl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Vamos importar a biblioteca do keras que abre modelos salvos previamente\n",
        "from keras.models import load_model\n",
        "\n",
        "#Agora abrimos o melhor modelo que geramos anteriormente\n",
        "\n",
        "melhor_modelo = load_model('Melhor_modelo.hdf5')\n",
        "\n",
        "print ('\\033[1m' + 'Etapa Concluída. Vá para o próximo comando!')\n",
        "\n",
        "#Execute esse código com SHIFT + ENTER"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D-N8kbE1UeBn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Usamos a função evaluate para avaliar a acurácia do nosso modelo no grupo de teste\n",
        "print('Acurácia no grupo de teste: ', melhor_modelo.evaluate(dataset_test, labels_test, verbose=0)[1])\n",
        "\n",
        "print ('\\n' + '\\033[1m' + 'Etapa Concluída. Vá para o próximo comando!')\n",
        "\n",
        "#Execute esse código com SHIFT + ENTER"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v9gffU3IUeBp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Podemos ver a predição caso a caso**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "jZjKyPSqUeBq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#Agora vemos fazer a inferência em imagens individuais do nosso dataset de teste.\n",
        "\n",
        "#Defina uma imagem no grupo de Teste, de 0 a 19:\n",
        "\n",
        "ID_imagem = 8\n",
        "\n",
        "#Agora vamos criar uma figura com a imagem escolhemos\n",
        "\n",
        "plt.imshow(np.squeeze(dataset_test[ID_imagem]), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "#Vamos mostrar a qual classe ela pertence\n",
        "\n",
        "print('Classe:', 'normal' if labels_test[ID_imagem]==0 else 'hematoma')\n",
        "\n",
        "predicao = np.round(melhor_modelo.predict(dataset_test[ID_imagem][np.newaxis,:,...], verbose=0))==0\n",
        "\n",
        "print('Predição:', 'normal' if predicao else 'hematoma')\n",
        "\n",
        "#Calcula o tempo médio de predição\n",
        "print('Tempo médio de predição:')\n",
        "%timeit melhor_modelo.predict(dataset_test[ID_imagem][np.newaxis,:,...], verbose=0)\n",
        "\n",
        "print ('\\n' + '\\033[1m' + 'Etapa Concluída. Vá para o próximo comando!')\n",
        "\n",
        "#Execute esse código com SHIFT + ENTER"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zAJV3_cGvIyA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install keras-vis\n",
        "\n",
        "print ('\\n' + '\\033[1m' + 'Etapa Concluída. Vá para o próximo comando!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3iVROnbBUX3e",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        },
        "cellView": "code"
      },
      "cell_type": "code",
      "source": [
        "#@title Default title text\n",
        "from vis.visualization import saliency\n",
        "from vis.visualization import activation_maximization\n",
        "from vis.visualization.__init__ import get_num_filters\n",
        "\n",
        "ID_imagem = 14\n",
        "\n",
        "Layer = -17\n",
        "\n",
        "#mapa = saliency.visualize_saliency(teste, Layer, filter_indices=range(get_num_filters(teste.layers[Layer])), seed_input=ds_test[ID_imagem], backprop_modifier=None, \\\n",
        "#    grad_modifier=\"absolute\")\n",
        "\n",
        "#mapa = activation_maximization.visualize_activation(teste, Layer, filter_indices=range(get_num_filters(teste.layers[Layer])), seed_input=ds_test[ID_imagem], \\\n",
        "#    backprop_modifier=None, grad_modifier=None, act_max_weight=1, lp_norm_weight=10, \\\n",
        "#    tv_weight=10)\n",
        "\n",
        "mapa = saliency.visualize_cam(melhor_modelo, Layer, filter_indices=range(get_num_filters(melhor_modelo.layers[Layer])), seed_input=dataset_test[ID_imagem], penultimate_layer_idx=Layer-1, \\\n",
        "    backprop_modifier=None, grad_modifier=None)\n",
        "\n",
        "plt.imshow(np.squeeze(dataset_test[ID_imagem]), cmap='gray')\n",
        "plt.show()\n",
        "plt.imshow(np.squeeze(mapa), cmap='jet')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "ID_imagem = 1\n",
        "\n",
        "Layer = -17\n",
        "\n",
        "#mapa = saliency.visualize_saliency(teste, Layer, filter_indices=range(get_num_filters(teste.layers[Layer])), seed_input=ds_test[ID_imagem], backprop_modifier=None, \\\n",
        "#    grad_modifier=\"absolute\")\n",
        "\n",
        "#mapa = activation_maximization.visualize_activation(teste, Layer, filter_indices=range(get_num_filters(teste.layers[Layer])), seed_input=ds_test[ID_imagem], \\\n",
        "#    backprop_modifier=None, grad_modifier=None, act_max_weight=1, lp_norm_weight=10, \\\n",
        "#    tv_weight=10)\n",
        "\n",
        "mapa = saliency.visualize_cam(melhor_modelo, Layer, filter_indices=range(get_num_filters(melhor_modelo.layers[Layer])), seed_input=dataset_test[ID_imagem], penultimate_layer_idx=Layer-1, \\\n",
        "    backprop_modifier=None, grad_modifier=None)\n",
        "\n",
        "plt.imshow(np.squeeze(dataset_test[ID_imagem]), cmap='gray')\n",
        "plt.show()\n",
        "plt.imshow(np.squeeze(mapa), cmap='jet')\n",
        "plt.show()\n",
        "\n",
        "print ('\\n' + '\\033[1m' + 'Etapa Concluída. Parabéns, você finalizou o Workshop!')\n",
        "\n",
        "from IPython.display import HTML\n",
        "HTML('<img src=\"https://media.giphy.com/media/cub3pntkz8muQ/giphy.gif\">')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}